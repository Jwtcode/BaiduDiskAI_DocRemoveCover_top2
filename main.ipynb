{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "# 百度网盘AI大赛-文档图片去遮挡比赛第3名方案\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 一、赛题分析\n",
    "此次大赛主题结合日常生活常见情景展开，人们在使用手机等移动设备扫描证件或者扫描文档、拍摄展示资料的场景中，经常会拍摄到一些手指或者人头等其他因素，对扫描成品的美观和易用性产生了影响。期望同学们通过计算机技术对给定文档图像进行处理，帮助人们去除文档图像中的手指、人头等因素，还原真实的文档资料，提升使用效率。\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 二、 数据分析\n",
    "- 本次比赛最新发布的数据集共包含训练集、A榜测试集、B榜测试集三个部分，其中训练集共14400组样本，A榜测试集共320个样本，B榜测试集共640个样本,抽取一部分数据如图：\n",
    "![image](https://github.com/Jwtcode/BaiduDiskAI_DocRemoveCover_top3/blob/master/illustration/0_IMG_20220705_103123_a.jpg)\n",
    "![image](https://github.com/Jwtcode/BaiduDiskAI_DocRemoveCover_top3/blob/master/illustration/0_IMG_20220705_103123_a_0_000.jpg)\n",
    "![image](https://github.com/Jwtcode/BaiduDiskAI_DocRemoveCover_top3/blob/master/illustration/0_IMG_20220705_103123_a_0_000.png)\n",
    "\n",
    "- hand,head 为带有手指、人头遮挡数据及遮挡部位分割图，gt 为非遮挡图片（仅有训练集数据提供gt ，A榜测试集、B榜测试集数据均不提供gt);\n",
    "- annotation.txt 为图片对应关系，每一行为一组样本，用空格分隔，分别为非遮挡图片、遮挡图片、分割图片;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 二、评价标准\n",
    "评价指标为 PSNR 和 MSSSIM；\n",
    "\n",
    "用于评价的机器环境仅提供两种框架模型运行环境：paddlepaddle 和 onnxruntime，其他框架模型可转换为\n",
    "上述两种框架的模型；\n",
    "\n",
    "机器配置：V100，显存16G，内存10G；\n",
    "\n",
    "单张图片耗时>2s，决赛中的性能分数记0分。\n",
    "\n",
    "由评价标准可知，不能使用大模型。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "# 三、模型设计\n",
    "\n",
    "针对图像去遮挡这个任务，我们查阅了相关资料，认为该任务是一个先擦出后重建优化的过程，所以我们选择了目前常用的EraseNet作为我们此次的baseline。整体思路分为预测目标所在位置，裁剪目标所在区域，初步去遮挡，去遮挡优化，生成mask，替换mask所在区域。\n",
    "- 预测目标所在位置：\n",
    "测试图片直接缩放成640x640进行预测并获得boundingbox。\n",
    "预测效果如图所示：\n",
    "- 裁剪目标所在区域\n",
    "这里分为以下几种情况：\n",
    "1）预测的boundingbox的宽高都小于1280\n",
    "   目标区域向四周扩充为1280x1280。\n",
    "2）预测的boundingbox的宽高有一个大于或者全都大于1280\n",
    "    大于1280的边长向外扩充为64的倍数即可（避免出现维度不匹配的情况出现）\n",
    "3）预测出多个boundingbox\n",
    "    将多个boundingbox按面积由大到小排序，面积最大的boundingbox最先扩充，如果后面的boundingbox包含在这个扩充的boundingbox里面，则不进行处理，如果不包含其中，将其扩充为同样的尺寸，保证输入到模型中的宽高一致。\n",
    "- 初步去遮挡\n",
    "    改进后的EraseNet去除了预测mask的分支（训练中发现预测mask和去遮挡有冲突），整体可以看成unet结构。\n",
    "- 去遮挡优化网络\n",
    "    去遮挡优化网络采用U型结构的自监督学习的idr网络，通过再次的编解码进行去遮挡的二次优化，得到最终的去遮挡图。\n",
    "- 生成mask\n",
    "    利用yolox预测的boundbox(不扩充)在优化后的去遮挡图上裁剪出目标区域，将裁下的图片与输入图片目标所在区域做差，差值的绝对值大于等于2的地方作为mask。\n",
    "- 替换mask所在区域\n",
    "    将mask在原图中的位置的像素替换为mask在去遮挡图位置的像素。\n",
    "\n",
    "![](![image](https://github.com/Jwtcode/BaiduDiskAI_DocRemoveCover_top3/blob/master/illustration/pipeline.png)\n",
    "\n",
    "从网络结构图上可以直观的看出改进后EraseNet变成了单分支网络，这是因为原版EraseNet的预测mask分支和第一阶段的Decoder存在冲突，所以我们去掉了预测mask分支，考虑到实效性，我们没有额外训练一个分割模型，而是选择检测模型(yolox)来获得mask。在损失函数上，原版的ErastNet使用了感知损失以及GAN损失，这个损失函数是为了生成更加逼真的背景，但是本赛题任务的背景都是纯色，所以这两个损失是不需要的。此外，EraseNet在多个尺度上使用了l1损失，我们只在第一阶段和第二阶段的最后一个尺度上使用了l1损失。此外，根据经验，我们将EraseNet的重建网络Refinement替换为了idr网络并在底层叠加了non-local结构。\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "# 四、数据处理与增强\n",
    "\n",
    "### 数据划分\n",
    "1）yolox:\n",
    "- 官方给的数据为14400张图片，所有图片直接缩放为640x640，其中12000张用于训练，2400张用于验证。\n",
    "利用数据集自带的mask生成yolo格式标签,选用yolox作为检测模型。\n",
    "2）EraseNet:\n",
    "- 官方给的数据为14400张图像，我们裁剪出包含遮挡物的图片为10800张（全部为正样本，尺寸为1024x1024），其中9000张用作训练，1800张用于验证。\n",
    "\n",
    "### 数据增广\n",
    "- 增强使用横向左右翻转和小角度旋转\n",
    "\n",
    "# 五、训练细节\n",
    "- 训练配置\n",
    "总迭代数：450000 iteration\n",
    "我们采用batch size为4和patch size为1024来进行训练450000次迭代。\n",
    "我们采用了余弦退火的学习率策略来优化网络，学习率我们采用1e-4，优化器为Adam。\n",
    "- 损失函数为L1Loss\n",
    "\n",
    "# 六、测试细节\n",
    "- 原图缩放为640x640输入到yolox网络中获得boundingbox，除以缩放比例获得在原图上的boundingbox，将boundingbox所在区域扩充得到去遮挡网络的输入。\n",
    "- 裁剪的图片输入到去遮挡网络中获得输出。\n",
    "- 输出与输入做差获得mask.\n",
    "- 将原图mask所在区域的像素值替换为输出mask所在区域的像素值。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 七、代码结构\n",
    "### erasenet_code:\n",
    "- dataloader: 定义数据增强函数和数据集\n",
    "- models: 定义网络模型\n",
    "- loss:定义损失函数\n",
    "- image_utils: 定义评价指标函数和其它函数\n",
    "- checkpoint: 模型训练输出文件夹\n",
    "- result:模型测试输出文件夹\n",
    "- test.py: 预测脚本\n",
    "- train.py: 训练脚本\n",
    "### yolox_code:\n",
    "- tools:训练测试脚本\n",
    "- weights:预训练权重\n",
    "- yolox:定义模型文件\n",
    "- YOLOX_outputs:模型输出\n",
    "- assets:测试图片存放位置\n",
    "### test_code:\n",
    "- predict.py: 预测脚本\n",
    "- DataProcess:前处理和后处理\n",
    "- model.onnx: 去遮挡网络最佳权重\n",
    "- my_yolox_s.onnx:检测网络最佳权重"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 八、上分策略\n",
    "\n",
    "![](https://ai-studio-static-online.cdn.bcebos.com/2bffa4513a1f498da0945379160fa87e420dd753765d4604bc5071e76e07de34)\n",
    "\n",
    "\n",
    "上分策略主要集中在数据清洗、推理速度优化和损失函数优化"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "请点击[此处](https://ai.baidu.com/docs#/AIStudio_Project_Notebook/a38e5576)查看本环境基本用法.  <br>\n",
    "Please click [here ](https://ai.baidu.com/docs#/AIStudio_Project_Notebook/a38e5576) for more detailed instructions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 代码启动过程\n",
    "## erasenet训练过程"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-07T01:16:31.851716Z",
     "iopub.status.busy": "2022-09-07T01:16:31.851238Z",
     "iopub.status.idle": "2022-09-07T01:18:25.142057Z",
     "shell.execute_reply": "2022-09-07T01:18:25.140650Z",
     "shell.execute_reply.started": "2022-09-07T01:16:31.851682Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^C\n"
     ]
    }
   ],
   "source": [
    "### 解压数据\n",
    "!cd datasets/ && unzip -q train*.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "##创建训练数据目录\n",
    "! mkdir -p datasets/IMG\n",
    "! mkdir -p datasets/TAR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/Users/jiaowt/Documents/BaiduDiskAI_DocRemoveCover_top3/main.ipynb Cell 14\u001b[0m in \u001b[0;36m<cell line: 11>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/jiaowt/Documents/BaiduDiskAI_DocRemoveCover_top3/main.ipynb#X16sZmlsZQ%3D%3D?line=28'>29</a>\u001b[0m tar_path\u001b[39m=\u001b[39mtar_filenames[i]\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/jiaowt/Documents/BaiduDiskAI_DocRemoveCover_top3/main.ipynb#X16sZmlsZQ%3D%3D?line=29'>30</a>\u001b[0m filename\u001b[39m=\u001b[39mos\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39msplit(mask_path)[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m]\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/jiaowt/Documents/BaiduDiskAI_DocRemoveCover_top3/main.ipynb#X16sZmlsZQ%3D%3D?line=30'>31</a>\u001b[0m mask_img\u001b[39m=\u001b[39mcv2\u001b[39m.\u001b[39;49mimread(mask_path,\u001b[39m0\u001b[39;49m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/jiaowt/Documents/BaiduDiskAI_DocRemoveCover_top3/main.ipynb#X16sZmlsZQ%3D%3D?line=31'>32</a>\u001b[0m inp_img\u001b[39m=\u001b[39mcv2\u001b[39m.\u001b[39mimread(inp_path)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/jiaowt/Documents/BaiduDiskAI_DocRemoveCover_top3/main.ipynb#X16sZmlsZQ%3D%3D?line=32'>33</a>\u001b[0m tar_img\u001b[39m=\u001b[39mcv2\u001b[39m.\u001b[39mimread(tar_path)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "##裁剪训练数据集\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "constprefix=\"train_data_\"\n",
    "rgb_dir='./datasets'\n",
    "IMG='./datasets/IMG'\n",
    "TAR='./datasets/TAR'\n",
    "#####裁剪尺寸为1024x1024\n",
    "BASE=1024\n",
    "for i in range(1,6):\n",
    "    image_path=os.path.join(rgb_dir,constprefix + str(i))\n",
    "    annotation_path=os.path.join(image_path,\"annotation.txt\")\n",
    "    tar_filenames=[]\n",
    "    inp_filenames=[]\n",
    "    mask_filenames=[]\n",
    "    with open (annotation_path,\"r\") as f:\n",
    "            data=f.read().splitlines()\n",
    "            for i in range (len(data)):\n",
    "                cur=data[i].split(' ')\n",
    "                tar_filenames.append(os.path.join(image_path,cur[0]))\n",
    "                inp_filenames.append(os.path.join(image_path,cur[1]))\n",
    "                mask_filenames.append(os.path.join(image_path,cur[2]))\n",
    "    \n",
    "    for i in range(len(mask_filenames)):\n",
    "    \n",
    "        mask_path=mask_filenames[i]\n",
    "        inp_path=inp_filenames[i]\n",
    "        tar_path=tar_filenames[i]\n",
    "        filename=os.path.split(mask_path)[-1]\n",
    "        mask_img=cv2.imread(mask_path,0)\n",
    "        inp_img=cv2.imread(inp_path)\n",
    "        tar_img=cv2.imread(tar_path)\n",
    "        H,W=mask_img.shape\n",
    "        mask_img[np.where(mask_img>40)]=255\n",
    "        mask_img[np.where(mask_img<40)]=0\n",
    "        contours, hierarchy = cv2.findContours(mask_img, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "        x, y, w, h = cv2.boundingRect(contours[0])\n",
    "        x1=x;x2=x+w;y1=y;y2=y+h;\n",
    "        w_add_half=BASE//2\n",
    "        h_add_half=BASE//2\n",
    "        x_mid=(x1+x2)//2\n",
    "        y_mid=(y1+y2)//2\n",
    "        if(x_mid-w_add_half<=0):\n",
    "            x1=0\n",
    "            x2=BASE\n",
    "        elif(x_mid+w_add_half>W):\n",
    "            x2=W\n",
    "            x1=W-BASE\n",
    "        else:\n",
    "            x1=x_mid-w_add_half\n",
    "            x2=x_mid+w_add_half\n",
    "        if(y_mid-h_add_half<=0):\n",
    "            y1=0\n",
    "            y2=BASE\n",
    "            \n",
    "        elif(y_mid+h_add_half>H):\n",
    "            y2=H\n",
    "            y1=H-BASE\n",
    "            \n",
    "        else:\n",
    "            y1=y_mid-h_add_half\n",
    "            y2=y_mid+h_add_half\n",
    "        inp_filename=os.path.split(inp_path)[-1]\n",
    "        tar_filename=inp_filename.split('.jpg')[0]+'_tar.jpg'\n",
    "        new_inp_path=os.path.join(IMG,inp_filename)\n",
    "        new_tar_path=os.path.join(TAR,tar_filename)\n",
    "        new_inp_img=inp_img[y1:y2,x1:x2,:]\n",
    "        new_tar_img=tar_img[y1:y2,x1:x2,:]\n",
    "        print(new_tar_path)\n",
    "        cv2.imwrite(new_inp_path,new_inp_img)\n",
    "        cv2.imwrite(new_tar_path,new_tar_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^C\n",
      "Looking in indexes: https://pypi.tuna.tsinghua.edu.cn/simple\n",
      "Requirement already satisfied: scikit-image in c:\\programdata\\anaconda3\\lib\\site-packages (0.18.1)\n",
      "Requirement already satisfied: numpy>=1.16.5 in c:\\programdata\\anaconda3\\lib\\site-packages (from scikit-image) (1.20.1)\n",
      "Requirement already satisfied: scipy>=1.0.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from scikit-image) (1.6.2)\n",
      "Requirement already satisfied: matplotlib!=3.0.0,>=2.0.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from scikit-image) (3.3.4)\n",
      "Requirement already satisfied: networkx>=2.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from scikit-image) (2.5)\n",
      "Requirement already satisfied: pillow!=7.1.0,!=7.1.1,>=4.3.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from scikit-image) (8.2.0)\n",
      "Requirement already satisfied: imageio>=2.3.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from scikit-image) (2.9.0)\n",
      "Requirement already satisfied: tifffile>=2019.7.26 in c:\\programdata\\anaconda3\\lib\\site-packages (from scikit-image) (2021.4.8)\n",
      "Requirement already satisfied: PyWavelets>=1.1.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from scikit-image) (1.1.1)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.3 in c:\\programdata\\anaconda3\\lib\\site-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image) (2.4.7)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image) (2.8.1)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image) (1.3.1)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\programdata\\anaconda3\\lib\\site-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image) (0.10.0)\n",
      "Requirement already satisfied: six in c:\\programdata\\anaconda3\\lib\\site-packages (from cycler>=0.10->matplotlib!=3.0.0,>=2.0.0->scikit-image) (1.15.0)\n",
      "Requirement already satisfied: decorator>=4.3.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from networkx>=2.0->scikit-image) (5.0.6)\n",
      "Looking in indexes: https://pypi.tuna.tsinghua.edu.cn/simple\n",
      "Collecting warmup_scheduler\n",
      "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/00/39/f77fb5a7a572891c1f4df1d8e1373a1380cb6d861933886334553244d002/warmup_scheduler-0.3.tar.gz (2.1 kB)\n",
      "Building wheels for collected packages: warmup-scheduler\n",
      "  Building wheel for warmup-scheduler (setup.py): started\n",
      "  Building wheel for warmup-scheduler (setup.py): finished with status 'done'\n",
      "  Created wheel for warmup-scheduler: filename=warmup_scheduler-0.3-py3-none-any.whl size=2998 sha256=e51155ddd5e11b5b054fc3308df854a41a5ec4e7f4f81ba9f62f2fe38d60363b\n",
      "  Stored in directory: c:\\users\\administrator\\appdata\\local\\pip\\cache\\wheels\\af\\09\\35\\3ef9059c328587fc37578f2e6b4039b3fbe6485a99ae9fc41e\n",
      "Successfully built warmup-scheduler\n",
      "Installing collected packages: warmup-scheduler\n",
      "Successfully installed warmup-scheduler-0.3\n",
      "Looking in indexes: https://pypi.tuna.tsinghua.edu.cn/simple\n",
      "Requirement already satisfied: pillow in c:\\programdata\\anaconda3\\lib\\site-packages (8.2.0)\n"
     ]
    }
   ],
   "source": [
    "## 安装训练所需的python包\n",
    "! pip install torch==1.8.1\n",
    "! pip install torchvision==0.9.1\n",
    "! pip install natsort  \n",
    "! pip install opencv-python\n",
    "! pip install scikit-image\n",
    "! pip install warmup_scheduler\n",
    "! pip install pillow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading weights into state dict...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"train.py\", line 24, in <module>\n",
      "    yolo = YOLO()\n",
      "  File \"c:\\Users\\Administrator\\Desktop\\BaiduDiskAI_DocRemoveCover_top3\\erasenet_code\\models\\yolo.py\", line 48, in __init__\n",
      "    self.generate()\n",
      "  File \"c:\\Users\\Administrator\\Desktop\\BaiduDiskAI_DocRemoveCover_top3\\erasenet_code\\models\\yolo.py\", line 77, in generate\n",
      "    self.net = self.net.cuda()\n",
      "  File \"c:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\", line 491, in cuda\n",
      "    return self._apply(lambda t: t.cuda(device))\n",
      "  File \"c:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\", line 387, in _apply\n",
      "    module._apply(fn)\n",
      "  File \"c:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\", line 387, in _apply\n",
      "    module._apply(fn)\n",
      "  File \"c:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\", line 409, in _apply\n",
      "    param_applied = fn(param)\n",
      "  File \"c:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\", line 491, in <lambda>\n",
      "    return self._apply(lambda t: t.cuda(device))\n",
      "  File \"c:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\cuda\\__init__.py\", line 164, in _lazy_init\n",
      "    raise AssertionError(\"Torch not compiled with CUDA enabled\")\n",
      "AssertionError: Torch not compiled with CUDA enabled\n"
     ]
    }
   ],
   "source": [
    "## 利用L1Loss训练\n",
    "! cd erasenet_code/ && python train.py "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## yolox训练过程"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "�����﷨����ȷ��\n",
      "�����﷨����ȷ��\n",
      "�����﷨����ȷ��\n",
      "�����﷨����ȷ��\n"
     ]
    }
   ],
   "source": [
    "##创建训练数据目录\n",
    "! mkdir -p datasets/VOCdevkit/VOC2007/Annotations\n",
    "! mkdir -p datasets/VOCdevkit/VOC2007/ImageSets\n",
    "! mkdir -p datasets/VOCdevkit/VOC2007/JPEGImages\n",
    "! mkdir -p datasets/VOCdevkit/VOC2007/Mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./datasets/VOCdevkit/VOC2007/JPEGImages/0_IMG_20220705_103123_a_0_000.jpg\n",
      "./datasets/VOCdevkit/VOC2007/JPEGImages/0_IMG_20220705_103123_a_0_001.jpg\n",
      "./datasets/VOCdevkit/VOC2007/JPEGImages/0_IMG_20220705_103123_a_0_002.jpg\n",
      "./datasets/VOCdevkit/VOC2007/JPEGImages/0_IMG_20220705_103123_a_0_003.jpg\n",
      "./datasets/VOCdevkit/VOC2007/JPEGImages/0_IMG_20220705_103123_a_0_004.jpg\n",
      "./datasets/VOCdevkit/VOC2007/JPEGImages/0_IMG_20220705_103123_a_0_005.jpg\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/Users/jiaowt/Documents/BaiduDiskAI_DocRemoveCover_top3/main.ipynb Cell 19\u001b[0m in \u001b[0;36m<cell line: 10>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/jiaowt/Documents/BaiduDiskAI_DocRemoveCover_top3/main.ipynb#X44sZmlsZQ%3D%3D?line=32'>33</a>\u001b[0m \u001b[39mprint\u001b[39m(new_inp_path)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/jiaowt/Documents/BaiduDiskAI_DocRemoveCover_top3/main.ipynb#X44sZmlsZQ%3D%3D?line=33'>34</a>\u001b[0m cv2\u001b[39m.\u001b[39mimwrite(new_inp_path,inp_img)\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/jiaowt/Documents/BaiduDiskAI_DocRemoveCover_top3/main.ipynb#X44sZmlsZQ%3D%3D?line=34'>35</a>\u001b[0m cv2\u001b[39m.\u001b[39;49mimwrite(new_mask_path,mask_img)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "##划分数据集\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "constprefix=\"train_data_\"\n",
    "rgb_dir='./datasets'\n",
    "inp='./datasets/VOCdevkit/VOC2007/JPEGImages'\n",
    "mask='./datasets/VOCdevkit/VOC2007/Mask'\n",
    "\n",
    "for i in range(1,6):\n",
    "    image_path=os.path.join(rgb_dir,constprefix + str(i))\n",
    "    annotation_path=os.path.join(image_path,\"annotation.txt\")\n",
    "    inp_filenames=[]\n",
    "    mask_filenames=[]\n",
    "    with open (annotation_path,\"r\") as f:\n",
    "            data=f.read().splitlines()\n",
    "            for i in range (len(data)):\n",
    "                cur=data[i].split(' ')\n",
    "                inp_filenames.append(os.path.join(image_path,cur[1]))\n",
    "                mask_filenames.append(os.path.join(image_path,cur[2]))\n",
    "    \n",
    "    for j in range(len(mask_filenames)):\n",
    "        mask_path=mask_filenames[j]\n",
    "        inp_path=inp_filenames[j]\n",
    "        mask_img=cv2.imread(mask_path,0)\n",
    "        inp_img=cv2.imread(inp_path)\n",
    "        mask_img[np.where(mask_img>40)]=255\n",
    "        mask_img[np.where(mask_img<40)]=0\n",
    "        inp_filename=os.path.split(inp_path)[-1]\n",
    "        mask_filename=os.path.split(mask_path)[-1]\n",
    "        new_inp_path=os.path.join(inp,inp_filename)\n",
    "        new_mask_path=os.path.join(mask,mask_filename)\n",
    "        cv2.imwrite(new_inp_path,inp_img)\n",
    "        cv2.imwrite(new_mask_path,mask_img)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "##mask2voc\n",
    "import os\n",
    "import numpy as np\n",
    "from itertools import groupby\n",
    "from skimage import morphology,measure\n",
    "from PIL import Image\n",
    "from scipy import misc\n",
    "import xml.etree.ElementTree as ET\n",
    "import os\n",
    "from pdb import set_trace as stx\n",
    "import copy\n",
    "\n",
    "def createXMLlabel(savedir,objectnum, contours, classname, foldername='0',filename='0', path='0', database='road', width='400', height='600',depth='3', segmented='0', pose=\"Unspecified\", truncated='0', difficult='0'):\n",
    "    # 创建根节点\n",
    "    root = ET.Element(\"annotation\")\n",
    " \n",
    "    # 创建子节点\n",
    "    folder_node = ET.Element(\"folder\")\n",
    "    folder_node.text = foldername\n",
    "    # 将子节点数据添加到根节点\n",
    "    root.append(folder_node)\n",
    " \n",
    "    file_node = ET.Element(\"filename\")\n",
    "    file_node.text = filename\n",
    "    root.append(file_node)\n",
    "    path_node = ET.Element(\"path\")\n",
    "    path_node.text = path\n",
    "    root.append(path_node)\n",
    " \n",
    "    source_node = ET.Element(\"source\")\n",
    "    # 也可以使用SubElement直接添加子节点\n",
    "    db_node = ET.SubElement(source_node, \"database\")\n",
    "    db_node.text = database\n",
    "    root.append(source_node)\n",
    " \n",
    "    size_node = ET.Element(\"size\")\n",
    "    width_node = ET.SubElement(size_node, \"width\")\n",
    "    height_node = ET.SubElement(size_node, \"height\")\n",
    "    depth_node = ET.SubElement(size_node, \"depth\")\n",
    "    width_node.text = width\n",
    "    height_node.text = height\n",
    "    depth_node.text = depth\n",
    "    root.append(size_node)\n",
    " \n",
    "    seg_node = ET.Element(\"segmented\")\n",
    "    seg_node.text = segmented\n",
    "    root.append(seg_node)\n",
    " \n",
    "    for i in range(objectnum):\n",
    "        x, y, w, h = cv2.boundingRect(contours[i]) \n",
    "        newEle = ET.Element(\"object\")\n",
    "        name = ET.Element(\"name\")\n",
    "        name.text = classname\n",
    "        newEle.append(name)\n",
    "        pose_node = ET.Element(\"pose\")\n",
    "        pose_node.text = pose\n",
    "        newEle.append(pose_node)\n",
    "        trunc = ET.Element(\"truncated\")\n",
    "        trunc.text = truncated\n",
    "        newEle.append(trunc)\n",
    "        dif = ET.Element(\"difficult\")\n",
    "        dif.text = difficult\n",
    "        newEle.append(dif)\n",
    "        boundingbox = ET.Element(\"bndbox\")\n",
    "        xmin = ET.SubElement(boundingbox, \"xmin\")\n",
    "        ymin = ET.SubElement(boundingbox, \"ymin\")\n",
    "        xmax = ET.SubElement(boundingbox, \"xmax\")\n",
    "        ymax = ET.SubElement(boundingbox, \"ymax\")\n",
    "        xmin.text = str(x)\n",
    "        ymin.text = str(y)\n",
    "        xmax.text = str(x + np.round(w).astype(int))\n",
    "        ymax.text = str(y + np.round(h).astype(int))\n",
    "        newEle.append(boundingbox)\n",
    "        root.append(newEle)\n",
    " \n",
    "    ImageID = filename.split('.')[0]\n",
    "    # 创建elementtree对象，写入文件\n",
    "    tree = ET.ElementTree(root)\n",
    "    tree.write(savedir + '/'+ ImageID + \".xml\")\n",
    "\n",
    "\n",
    "if __name__==\"__main__\":\n",
    "    import cv2\n",
    "    imagedir = './datasets/VOCdevkit/VOC2007/Mask'\n",
    "    saveXMLdir = './datasets/VOCdevkit/VOC2007/Annotations'\n",
    "    if os.path.exists(saveXMLdir) is False:\n",
    "        os.mkdir(saveXMLdir)\n",
    "\n",
    "    for fname in sorted(os.listdir(imagedir)):\n",
    "        labelpath = os.path.join(imagedir, fname)\n",
    "        image = cv2.imread(labelpath,0)\n",
    "        # 得到label图上的boundingingbox和数量\n",
    "   \n",
    "        contours, hierarchy = cv2.findContours(image, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "        objectnum=len(contours)\n",
    "        # label图 命名格式为 ImgeID_classname.png\n",
    "        # for i in range(objectnum):\n",
    "        #     x, y, w, h = cv2.boundingRect(contours[i])\n",
    "        #     cv2.rectangle(image, (x, y), (x + w, y + h), (255, 0, 0), 2)\n",
    "        \n",
    "        ImageID = os.path.split(labelpath)[-1].split('.png')[0]\n",
    "        classname = 'hh'\n",
    "        origin_image_name = ImageID +'.jpg'\n",
    "\n",
    "        # 一些图片信息\n",
    "        foldername = 'test_dataset'\n",
    "        path  ='./datasets/VOCdevkit/VOC2007/JPEGImages/'+ origin_image_name\n",
    "        database = 'Unknown'\n",
    "        width = str(image.shape[0])\n",
    "        height = str(image.shape[1])\n",
    "        depth = str(1)\n",
    "\n",
    "        createXMLlabel(saveXMLdir,objectnum, contours, classname, foldername=foldername,filename=origin_image_name, path=path,\n",
    "                    database=database, width=width, height=height,depth=depth, segmented='0', pose=\"Unspecified\",\n",
    "                    truncated='0', difficult='0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train and val size 4\n",
      "traub suze 4\n"
     ]
    }
   ],
   "source": [
    "##voc2yolo\n",
    "import os\n",
    "import random\n",
    "random.seed(0)\n",
    " \n",
    "xmlfilepath = r'./datasets/VOCdevkit/VOC2007/Annotations'\n",
    "saveBasePath = r\"./datasets/VOCdevkit/VOC2007/ImageSets/Main\"\n",
    " \n",
    "trainval_percent = 0.8\n",
    "train_percent = 1\n",
    " \n",
    "temp_xml = os.listdir(xmlfilepath)\n",
    "total_xml = []\n",
    "for xml in temp_xml:\n",
    "    if xml.endswith(\".xml\"):\n",
    "        total_xml.append(xml)\n",
    " \n",
    "num = len(total_xml)\n",
    "list = range(num)\n",
    "tv = int(num*trainval_percent)\n",
    "tr = int(tv*train_percent)\n",
    "trainval = random.sample(list, tv)\n",
    "train = random.sample(trainval, tr)\n",
    " \n",
    "print(\"train and val size\", tv)\n",
    "print(\"traub suze\", tr)\n",
    "ftrainval = open(os.path.join(saveBasePath, 'trainval.txt'), 'w')\n",
    "ftest = open(os.path.join(saveBasePath, 'test.txt'), 'w')\n",
    "ftrain = open(os.path.join(saveBasePath, 'train.txt'), 'w')\n",
    "fval = open(os.path.join(saveBasePath, 'val.txt'), 'w')\n",
    " \n",
    "for i in list:\n",
    "    name = total_xml[i][:-4]+'\\n'\n",
    "    if i in trainval:\n",
    "        ftrainval.write(name)\n",
    "        if i in train:\n",
    "            ftrain.write(name)\n",
    "        else:\n",
    "            fval.write(name)\n",
    "    else:\n",
    "        ftest.write(name)\n",
    " \n",
    "ftrainval.close()\n",
    "ftrain.close()\n",
    "fval.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.tuna.tsinghua.edu.cn/simple\n",
      "Requirement already satisfied: loguru in c:\\programdata\\anaconda3\\lib\\site-packages (0.6.0)\n",
      "Requirement already satisfied: win32-setctime>=1.0.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from loguru) (1.1.0)\n",
      "Requirement already satisfied: colorama>=0.3.4 in c:\\programdata\\anaconda3\\lib\\site-packages (from loguru) (0.4.4)\n",
      "Looking in indexes: https://pypi.tuna.tsinghua.edu.cn/simple\n",
      "Requirement already satisfied: tensorboard in c:\\programdata\\anaconda3\\lib\\site-packages (2.10.1)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorboard) (0.4.6)\n",
      "Requirement already satisfied: protobuf<3.20,>=3.9.2 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorboard) (3.19.6)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorboard) (2.25.1)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorboard) (3.4.1)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorboard) (1.8.1)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorboard) (52.0.0.post20210125)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorboard) (1.0.1)\n",
      "Requirement already satisfied: grpcio>=1.24.3 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorboard) (1.49.1)\n",
      "Requirement already satisfied: numpy>=1.12.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorboard) (1.20.1)\n",
      "Requirement already satisfied: absl-py>=0.4 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorboard) (1.2.0)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorboard) (2.12.0)\n",
      "Requirement already satisfied: wheel>=0.26 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorboard) (0.36.2)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorboard) (0.6.1)\n",
      "Requirement already satisfied: six>=1.9.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard) (1.15.0)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard) (5.2.0)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard) (0.2.8)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\programdata\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard) (4.9)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard) (1.3.1)\n",
      "Requirement already satisfied: importlib-metadata>=4.4 in c:\\programdata\\anaconda3\\lib\\site-packages (from markdown>=2.6.8->tensorboard) (5.0.0)\n",
      "Requirement already satisfied: zipp>=0.5 in c:\\programdata\\anaconda3\\lib\\site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard) (3.4.1)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in c:\\programdata\\anaconda3\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard) (0.4.8)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard) (4.0.0)\n",
      "Requirement already satisfied: idna<3,>=2.5 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard) (2.10)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard) (1.26.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard) (2020.12.5)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard) (3.2.1)\n",
      "Looking in indexes: https://pypi.tuna.tsinghua.edu.cn/simple\n",
      "Collecting pycocotools\n",
      "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/95/4c/28abd74a0338f27a6a6491d3bc82d00b636028295d9a8ffc5bb0fd62c9bd/pycocotools-2.0.5.tar.gz (24 kB)\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "    Preparing wheel metadata: started\n",
      "    Preparing wheel metadata: finished with status 'done'\n",
      "Requirement already satisfied: matplotlib>=2.1.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from pycocotools) (3.3.4)\n",
      "Requirement already satisfied: numpy in c:\\programdata\\anaconda3\\lib\\site-packages (from pycocotools) (1.20.1)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from matplotlib>=2.1.0->pycocotools) (2.8.1)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.3 in c:\\programdata\\anaconda3\\lib\\site-packages (from matplotlib>=2.1.0->pycocotools) (2.4.7)\n",
      "Requirement already satisfied: pillow>=6.2.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from matplotlib>=2.1.0->pycocotools) (8.2.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from matplotlib>=2.1.0->pycocotools) (1.3.1)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\programdata\\anaconda3\\lib\\site-packages (from matplotlib>=2.1.0->pycocotools) (0.10.0)\n",
      "Requirement already satisfied: six in c:\\programdata\\anaconda3\\lib\\site-packages (from cycler>=0.10->matplotlib>=2.1.0->pycocotools) (1.15.0)\n",
      "Building wheels for collected packages: pycocotools\n",
      "  Building wheel for pycocotools (PEP 517): started\n",
      "  Building wheel for pycocotools (PEP 517): finished with status 'error'\n",
      "Failed to build pycocotools\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  ERROR: Command errored out with exit status 1:\n",
      "   command: 'C:\\ProgramData\\Anaconda3\\python.exe' 'C:\\ProgramData\\Anaconda3\\lib\\site-packages\\pip\\_vendor\\pep517\\_in_process.py' build_wheel 'C:\\Users\\Administrator\\AppData\\Local\\Temp\\tmpe5w_mwk4'\n",
      "       cwd: C:\\Users\\Administrator\\AppData\\Local\\Temp\\pip-install-wo3m8gba\\pycocotools_46172c95f4da41849319517e4ced8d23\n",
      "  Complete output (16 lines):\n",
      "  running bdist_wheel\n",
      "  running build\n",
      "  running build_py\n",
      "  creating build\n",
      "  creating build\\lib.win-amd64-cpython-38\n",
      "  creating build\\lib.win-amd64-cpython-38\\pycocotools\n",
      "  copying pycocotools\\coco.py -> build\\lib.win-amd64-cpython-38\\pycocotools\n",
      "  copying pycocotools\\cocoeval.py -> build\\lib.win-amd64-cpython-38\\pycocotools\n",
      "  copying pycocotools\\mask.py -> build\\lib.win-amd64-cpython-38\\pycocotools\n",
      "  copying pycocotools\\__init__.py -> build\\lib.win-amd64-cpython-38\\pycocotools\n",
      "  running build_ext\n",
      "  cythoning pycocotools/_mask.pyx to pycocotools\\_mask.c\n",
      "  C:\\Users\\Administrator\\AppData\\Local\\Temp\\pip-build-env-msnjxw9m\\overlay\\Lib\\site-packages\\Cython\\Compiler\\Main.py:369: FutureWarning: Cython directive 'language_level' not set, using 2 for now (Py2). This will change in a later release! File: C:\\Users\\Administrator\\AppData\\Local\\Temp\\pip-install-wo3m8gba\\pycocotools_46172c95f4da41849319517e4ced8d23\\pycocotools\\_mask.pyx\n",
      "    tree = Parsing.p_module(s, pxd, full_module_name)\n",
      "  building 'pycocotools._mask' extension\n",
      "  error: Microsoft Visual C++ 14.0 or greater is required. Get it with \"Microsoft C++ Build Tools\": https://visualstudio.microsoft.com/visual-cpp-build-tools/\n",
      "  ----------------------------------------\n",
      "  ERROR: Failed building wheel for pycocotools\n",
      "ERROR: Could not build wheels for pycocotools which use PEP 517 and cannot be installed directly\n"
     ]
    }
   ],
   "source": [
    "## 安装训练所需的python包\n",
    "! pip install loguru\n",
    "! pip install tensorboard\n",
    "! pip install pycocotools\n",
    "! pip install tabulate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\cuda\\amp\\grad_scaler.py:116: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\"torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\")\n",
      "\u001b[32m2022-10-13 20:06:43\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m130\u001b[0m - \u001b[1margs: Namespace(batch_size=8, cache=False, ckpt='weights/yolox_s.pth', devices=0, dist_backend='nccl', dist_url=None, exp_file='exps/example/yolox_voc/yolox_voc_s.py', experiment_name='yolox_voc_s', fp16=True, logger='tensorboard', machine_rank=0, name=None, num_machines=1, occupy=True, opts=[], resume=False, start_epoch=None)\u001b[0m\n",
      "\u001b[32m2022-10-13 20:06:43\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m131\u001b[0m - \u001b[1mexp value:\n",
      "╒═══════════════════╤════════════════════════════╕\n",
      "│ keys              │ values                     │\n",
      "╞═══════════════════╪════════════════════════════╡\n",
      "│ seed              │ None                       │\n",
      "├───────────────────┼────────────────────────────┤\n",
      "│ output_dir        │ './YOLOX_outputs'          │\n",
      "├───────────────────┼────────────────────────────┤\n",
      "│ print_interval    │ 10                         │\n",
      "├───────────────────┼────────────────────────────┤\n",
      "│ eval_interval     │ 10                         │\n",
      "├───────────────────┼────────────────────────────┤\n",
      "│ num_classes       │ 1                          │\n",
      "├───────────────────┼────────────────────────────┤\n",
      "│ depth             │ 0.33                       │\n",
      "├───────────────────┼────────────────────────────┤\n",
      "│ width             │ 0.5                        │\n",
      "├───────────────────┼────────────────────────────┤\n",
      "│ act               │ 'silu'                     │\n",
      "├───────────────────┼────────────────────────────┤\n",
      "│ data_num_workers  │ 4                          │\n",
      "├───────────────────┼────────────────────────────┤\n",
      "│ input_size        │ (640, 640)                 │\n",
      "├───────────────────┼────────────────────────────┤\n",
      "│ multiscale_range  │ 5                          │\n",
      "├───────────────────┼────────────────────────────┤\n",
      "│ data_dir          │ None                       │\n",
      "├───────────────────┼────────────────────────────┤\n",
      "│ train_ann         │ 'instances_train2017.json' │\n",
      "├───────────────────┼────────────────────────────┤\n",
      "│ val_ann           │ 'instances_val2017.json'   │\n",
      "├───────────────────┼────────────────────────────┤\n",
      "│ test_ann          │ 'instances_test2017.json'  │\n",
      "├───────────────────┼────────────────────────────┤\n",
      "│ mosaic_prob       │ 1.0                        │\n",
      "├───────────────────┼────────────────────────────┤\n",
      "│ mixup_prob        │ 1.0                        │\n",
      "├───────────────────┼────────────────────────────┤\n",
      "│ hsv_prob          │ 1.0                        │\n",
      "├───────────────────┼────────────────────────────┤\n",
      "│ flip_prob         │ 0.5                        │\n",
      "├───────────────────┼────────────────────────────┤\n",
      "│ degrees           │ 10.0                       │\n",
      "├───────────────────┼────────────────────────────┤\n",
      "│ translate         │ 0.1                        │\n",
      "├───────────────────┼────────────────────────────┤\n",
      "│ mosaic_scale      │ (0.1, 2)                   │\n",
      "├───────────────────┼────────────────────────────┤\n",
      "│ enable_mixup      │ True                       │\n",
      "├───────────────────┼────────────────────────────┤\n",
      "│ mixup_scale       │ (0.5, 1.5)                 │\n",
      "├───────────────────┼────────────────────────────┤\n",
      "│ shear             │ 2.0                        │\n",
      "├───────────────────┼────────────────────────────┤\n",
      "│ warmup_epochs     │ 1                          │\n",
      "├───────────────────┼────────────────────────────┤\n",
      "│ max_epoch         │ 300                        │\n",
      "├───────────────────┼────────────────────────────┤\n",
      "│ warmup_lr         │ 0                          │\n",
      "├───────────────────┼────────────────────────────┤\n",
      "│ min_lr_ratio      │ 0.05                       │\n",
      "├───────────────────┼────────────────────────────┤\n",
      "│ basic_lr_per_img  │ 0.00015625                 │\n",
      "├───────────────────┼────────────────────────────┤\n",
      "│ scheduler         │ 'yoloxwarmcos'             │\n",
      "├───────────────────┼────────────────────────────┤\n",
      "│ no_aug_epochs     │ 15                         │\n",
      "├───────────────────┼────────────────────────────┤\n",
      "│ ema               │ True                       │\n",
      "├───────────────────┼────────────────────────────┤\n",
      "│ weight_decay      │ 0.0005                     │\n",
      "├───────────────────┼────────────────────────────┤\n",
      "│ momentum          │ 0.9                        │\n",
      "├───────────────────┼────────────────────────────┤\n",
      "│ save_history_ckpt │ True                       │\n",
      "├───────────────────┼────────────────────────────┤\n",
      "│ exp_name          │ 'yolox_voc_s'              │\n",
      "├───────────────────┼────────────────────────────┤\n",
      "│ test_size         │ (640, 640)                 │\n",
      "├───────────────────┼────────────────────────────┤\n",
      "│ test_conf         │ 0.01                       │\n",
      "├───────────────────┼────────────────────────────┤\n",
      "│ nmsthre           │ 0.65                       │\n",
      "╘═══════════════════╧════════════════════════════╛\u001b[0m\n",
      "\u001b[32m2022-10-13 20:06:43\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36myolox.core.launch\u001b[0m:\u001b[36m98\u001b[0m - \u001b[31m\u001b[1mAn error has been caught in function 'launch', process 'MainProcess' (3644), thread 'MainThread' (11776):\u001b[0m\n",
      "\u001b[33m\u001b[1mTraceback (most recent call last):\u001b[0m\n",
      "\n",
      "  File \"\u001b[32mtools\\\u001b[0m\u001b[32m\u001b[1mtrain.py\u001b[0m\", line \u001b[33m134\u001b[0m, in \u001b[35m<module>\u001b[0m\n",
      "    \u001b[1mlaunch\u001b[0m\u001b[1m(\u001b[0m\n",
      "    \u001b[36m└ \u001b[0m\u001b[36m\u001b[1m<function launch at 0x0000024EA8EEE040>\u001b[0m\n",
      "\n",
      "> File \"\u001b[32m../yolox_code\\yolox\\core\\\u001b[0m\u001b[32m\u001b[1mlaunch.py\u001b[0m\", line \u001b[33m98\u001b[0m, in \u001b[35mlaunch\u001b[0m\n",
      "    \u001b[1mmain_func\u001b[0m\u001b[1m(\u001b[0m\u001b[35m\u001b[1m*\u001b[0m\u001b[1margs\u001b[0m\u001b[1m)\u001b[0m\n",
      "    \u001b[36m│          └ \u001b[0m\u001b[36m\u001b[1m(╒═══════════════════╤════════════════════════════╕\u001b[0m\n",
      "    \u001b[36m│            \u001b[0m\u001b[36m\u001b[1m│ keys              │ values                     │\u001b[0m\n",
      "    \u001b[36m│            \u001b[0m\u001b[36m\u001b[1m╞═══════════════════╪═...\u001b[0m\n",
      "    \u001b[36m└ \u001b[0m\u001b[36m\u001b[1m<function main at 0x0000024EA9498940>\u001b[0m\n",
      "\n",
      "  File \"\u001b[32mtools\\\u001b[0m\u001b[32m\u001b[1mtrain.py\u001b[0m\", line \u001b[33m118\u001b[0m, in \u001b[35mmain\u001b[0m\n",
      "    \u001b[1mtrainer\u001b[0m\u001b[35m\u001b[1m.\u001b[0m\u001b[1mtrain\u001b[0m\u001b[1m(\u001b[0m\u001b[1m)\u001b[0m\n",
      "    \u001b[36m│       └ \u001b[0m\u001b[36m\u001b[1m<function Trainer.train at 0x0000024EAC083D30>\u001b[0m\n",
      "    \u001b[36m└ \u001b[0m\u001b[36m\u001b[1m<yolox.core.trainer.Trainer object at 0x0000024EAC089CA0>\u001b[0m\n",
      "\n",
      "  File \"\u001b[32m../yolox_code\\yolox\\core\\\u001b[0m\u001b[32m\u001b[1mtrainer.py\u001b[0m\", line \u001b[33m74\u001b[0m, in \u001b[35mtrain\u001b[0m\n",
      "    \u001b[1mself\u001b[0m\u001b[35m\u001b[1m.\u001b[0m\u001b[1mbefore_train\u001b[0m\u001b[1m(\u001b[0m\u001b[1m)\u001b[0m\n",
      "    \u001b[36m│    └ \u001b[0m\u001b[36m\u001b[1m<function Trainer.before_train at 0x0000024EAC0875E0>\u001b[0m\n",
      "    \u001b[36m└ \u001b[0m\u001b[36m\u001b[1m<yolox.core.trainer.Trainer object at 0x0000024EAC089CA0>\u001b[0m\n",
      "\n",
      "  File \"\u001b[32m../yolox_code\\yolox\\core\\\u001b[0m\u001b[32m\u001b[1mtrainer.py\u001b[0m\", line \u001b[33m134\u001b[0m, in \u001b[35mbefore_train\u001b[0m\n",
      "    \u001b[1mtorch\u001b[0m\u001b[35m\u001b[1m.\u001b[0m\u001b[1mcuda\u001b[0m\u001b[35m\u001b[1m.\u001b[0m\u001b[1mset_device\u001b[0m\u001b[1m(\u001b[0m\u001b[1mself\u001b[0m\u001b[35m\u001b[1m.\u001b[0m\u001b[1mlocal_rank\u001b[0m\u001b[1m)\u001b[0m\n",
      "    \u001b[36m│     │    │          │    └ \u001b[0m\u001b[36m\u001b[1m0\u001b[0m\n",
      "    \u001b[36m│     │    │          └ \u001b[0m\u001b[36m\u001b[1m<yolox.core.trainer.Trainer object at 0x0000024EAC089CA0>\u001b[0m\n",
      "    \u001b[36m│     │    └ \u001b[0m\u001b[36m\u001b[1m<function set_device at 0x0000024EA8666430>\u001b[0m\n",
      "    \u001b[36m│     └ \u001b[0m\u001b[36m\u001b[1m<module 'torch.cuda' from 'c:\\\\ProgramData\\\\Anaconda3\\\\lib\\\\site-packages\\\\torch\\\\cuda\\\\__init__.py'>\u001b[0m\n",
      "    \u001b[36m└ \u001b[0m\u001b[36m\u001b[1m<module 'torch' from 'c:\\\\ProgramData\\\\Anaconda3\\\\lib\\\\site-packages\\\\torch\\\\__init__.py'>\u001b[0m\n",
      "\n",
      "  File \"\u001b[32mc:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\cuda\\\u001b[0m\u001b[32m\u001b[1m__init__.py\u001b[0m\", line \u001b[33m261\u001b[0m, in \u001b[35mset_device\u001b[0m\n",
      "    \u001b[1mtorch\u001b[0m\u001b[35m\u001b[1m.\u001b[0m\u001b[1m_C\u001b[0m\u001b[35m\u001b[1m.\u001b[0m\u001b[1m_cuda_setDevice\u001b[0m\u001b[1m(\u001b[0m\u001b[1mdevice\u001b[0m\u001b[1m)\u001b[0m\n",
      "    \u001b[36m│     │                  └ \u001b[0m\u001b[36m\u001b[1m0\u001b[0m\n",
      "    \u001b[36m│     └ \u001b[0m\u001b[36m\u001b[1m<module 'torch._C' from 'c:\\\\ProgramData\\\\Anaconda3\\\\lib\\\\site-packages\\\\torch\\\\_C.cp38-win_amd64.pyd'>\u001b[0m\n",
      "    \u001b[36m└ \u001b[0m\u001b[36m\u001b[1m<module 'torch' from 'c:\\\\ProgramData\\\\Anaconda3\\\\lib\\\\site-packages\\\\torch\\\\__init__.py'>\u001b[0m\n",
      "\n",
      "\u001b[31m\u001b[1mAttributeError\u001b[0m:\u001b[1m module 'torch._C' has no attribute '_cuda_setDevice'\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "## 训练yolox\n",
    "! cd yolox_code/ && python tools/train.py -f exps/example/yolox_voc/yolox_voc_s.py -d 0 -b 8 --fp16 -o -c weights/yolox_s.pth \n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 预测过程\n",
    "按照官方给定的预测脚本运行方式相同，将最终的finetuning模型改名为model.pdparams，并且放在predict.py的同意目录下，使用命令：\n",
    "```\n",
    "python predict.py [src_image_dir] [results]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.8.2 64-bit' requires ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '/usr/bin/python3 -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "## 测试脚本\n",
    "! cd test_code/ && python predict.py {your_test_data_path} {save_path}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.8 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "vscode": {
   "interpreter": {
    "hash": "ad2bdc8ecc057115af97d19610ffacc2b4e99fae6737bb82f5d7fb13d2f2c186"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
